# Week 6-7 â€” Deploying Serverless Containers

## Defaults

Before we start with the implementation, we need to set some default values for our AWS resources. The following scripts will set the default VPC ID and subnet IDs in our environment variables:

```sh
export DEFAULT_VPC_ID=$(aws ec2 describe-vpcs \
--filters "Name=isDefault, Values=true" \
--query "Vpcs[0].VpcId" \
--output text)
echo $DEFAULT_VPC_ID
```

```sh
export DEFAULT_SUBNET_IDS=$(aws ec2 describe-subnets  \
 --filters Name=vpc-id,Values=$DEFAULT_VPC_ID \
 --query 'Subnets[*].SubnetId' \
 --output json | jq -r 'join(",")')
echo $DEFAULT_SUBNET_IDS
```

These scripts will retrieve the default VPC ID and subnet IDs of the VPC that our AWS resources are using. We will use these default values in our implementation.

## Test RDS Connection
Before we proceed with the implementation, we need to test our RDS connection. We will add a test script to our db directory, which will allow us to easily check our connection from our container. The following script will attempt to connect to the database specified in the CONNECTION_URL environment variable:

```py
#!/usr/bin/env python3

import psycopg
import os
import sys

connection_url = os.getenv("CONNECTION_URL")

conn = None
try:
  print('attempting connection')
  conn = psycopg.connect(connection_url)
  print("Connection successful!")
except psycopg.Error as e:
  print("Unable to connect to the database:", e)
finally:
  conn.close()
```

## Task Flask Script
Next, we will add an endpoint for our Flask app. The following endpoint will be added to our Flask app:

```py
@app.route('/api/health-check')
def health_check():
  return {'success': True}, 200
```

We will create a new bin script at bin/flask/health-check, which will check if the Flask server is running:

```py

#!/usr/bin/env python3

import urllib.request

response = urllib.request.urlopen('http://localhost:4567/api/health-check')
if response.getcode() == 200:
  print("Flask server is running")
else:
  print("Flask server is not running")
```

## Create CloudWatch Log Group
Finally, we will create a CloudWatch log group for our application. The following script will create a log group named cruddur and set the retention policy to 1 day:

```sh
aws logs create-log-group --log-group-name cruddur
aws logs put-retention-policy --log-group-name cruddur --retention-in-days 1
```

This log group will be used to store logs generated by our application.

## Create ECS Cluster
First, we will create an ECS cluster named cruddur and set the service connect defaults namespace to cruddur using the following script:

```sh

aws ecs create-cluster \
--cluster-name cruddur \
--service-connect-defaults namespace=cruddur
```

Next, we will create a security group for our ECS cluster using the following script:

```sh

export CRUD_CLUSTER_SG=$(aws ec2 create-security-group \
  --group-name cruddur-ecs-cluster-sg \
  --description "Security group for Cruddur ECS ECS cluster" \
  --vpc-id $DEFAULT_VPC_ID \
  --query "GroupId" --output text)
echo $CRUD_CLUSTER_SG
```

After the security group has been created, we can retrieve the group ID using the following script:

```sh

export CRUD_CLUSTER_SG=$(aws ec2 describe-security-groups \
--group-names cruddur-ecs-cluster-sg \
--query 'SecurityGroups[0].GroupId' \
--output text)
```
### Gaining Access to ECS Fargate Container
Next, we need to gain access to our ECS Fargate container. We can do this by configuring the task definition for our ECS service. We will create a task definition that specifies the Docker image to use and the resources required by the container.

### Create ECR Repo and Push Image
Before we can create the task definition, we need to create an ECR repo and push our Docker image to it. First, we need to login to ECR using the following script:

```sh

aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin "$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"
```

Next, we will create an ECR repo named cruddur-python with the image tag mutability set to MUTABLE using the following script:

```sh

aws ecr create-repository \
  --repository-name cruddur-python \
  --image-tag-mutability MUTABLE
```

After the repo has been created, we can set the URL for the repo using the following script:

```sh

export ECR_PYTHON_URL="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/cruddur-python"
echo $ECR_PYTHON_URL
```
Next, we will pull the python:3.10-slim-buster base image from Docker Hub using the following script:

```sh

docker pull python:3.10-slim-buster
```
After the image has been pulled, we can tag it with the ECR repo URL using the following script:

```sh

docker tag python:3.10-slim-buster $ECR_PYTHON_URL:3.10-slim-buster
```
Finally, we can push the Docker image to ECR using the following script:

```sh

docker push $ECR_PYTHON_URL:3.10-slim-buster
```

### For Flask
To build a Docker image for our Flask application, we need to update the FROM statement in the Dockerfile to use our own Python image. We can create an ECR repo for our Flask Docker image using the following script:

```sh

aws ecr create-repository \
  --repository-name backend-flask \
  --image-tag-mutability MUTABLE
```

After the repo has been created, we can set the URL for the repo using the following script:

```sh

export ECR_BACKEND_FLASK_URL="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/backend-flask"
echo $ECR_BACKEND_FLASK_URL
```

Next, we will build the Docker image for our Flask application using the following script:

```sh

docker build -t backend-flask .
```

After the image has been built, we can tag it with the ECR repo URL using the following script:

```sh

docker tag backend-flask:latest $ECR_BACKEND_FLASK_URL:latest
```
Finally, we can push the Docker image to ECR using the following script:

```sh

docker push $ECR_BACKEND_FLASK_URL:latest
```

### For Frontend React
To build a Docker image for our React application, we can create an ECR repo for it using the following script:

```sh

aws ecr create-repository \
  --repository-name frontend-react-js \
  --image-tag-mutability MUTABLE
```

After the repo has been created, we can set the URL for the repo using the following script:

```sh

export ECR_FRONTEND_REACT_URL="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/frontend-react-js"
echo $ECR_FRONTEND_REACT_URL
```
Next, we will build the Docker image for our React application using the following script:

```sh

docker build \
--build-arg REACT_APP_BACKEND_URL="https://4567-$GITPOD_WORKSPACE_ID.$GITPOD_WORKSPACE_CLUSTER_HOST" \
--build-arg REACT_APP_AWS_PROJECT_REGION="$AWS_DEFAULT_REGION" \
--build-arg REACT_APP_AWS_COGNITO_REGION="$AWS_DEFAULT_REGION" \
--build-arg REACT_APP_AWS_USER_POOLS_ID="ca-central-1_CQ4wDfnwc" \
--build-arg REACT_APP_CLIENT_ID="5b6ro31g97urk767adrbrdj1g5" \
-t frontend-react-js \
-f Dockerfile.prod \
.
```
After the image has been built, we can tag it with the ECR repo URL using the following script:

```sh

docker tag frontend-react-js:latest $ECR_FRONTEND_REACT_URL:latest
```
Finally, we can push the Docker image to ECR using the following script:

```sh

docker push $ECR_FRONTEND_REACT_URL:latest
```
If we want to run and test our React application using the Docker image, we can use the following script:

```sh

docker run --rm -p 3000:3000 -it frontend-react-js 
```
Note that this will start a container that listens on port 3000, so we can access the application by visiting http://localhost:3000 in our web browser.

### Passing Sensitive Data to Task Definition
We can use AWS Systems Manager Parameter Store to securely store and manage our sensitive data such as credentials, tokens, and connection strings. We can then pass these values to our task definition as environment variables.

To store sensitive data in the Parameter Store, we can use the following script:

```sh

aws ssm put-parameter --type "SecureString" --name "/cruddur/backend-flask/AWS_ACCESS_KEY_ID" --value $AWS_ACCESS_KEY_ID
aws ssm put-parameter --type "SecureString" --name "/cruddur/backend-flask/AWS_SECRET_ACCESS_KEY" --value $AWS_SECRET_ACCESS_KEY
aws ssm put-parameter --type "SecureString" --name "/cruddur/backend-flask/CONNECTION_URL" --value $PROD_CONNECTION_URL
aws ssm put-parameter --type "SecureString" --name "/cruddur/backend-flask/ROLLBAR_ACCESS_TOKEN" --value $ROLLBAR_ACCESS_TOKEN
aws ssm put-parameter --type "SecureString" --name "/cruddur/backend-flask/OTEL_EXPORTER_OTLP_HEADERS" --value "x-honeycomb-team=$HONEYCOMB_API_KEY"
```
We can then reference these values in our task definition as follows:

```json
{
  "name": "backend-flask",
  "image": "backend-flask:latest",
  "secrets": [
    {
      "name": "AWS_ACCESS_KEY_ID",
      "valueFrom": "/cruddur/backend-flask/AWS_ACCESS_KEY_ID"
    },
    {
      "name": "AWS_SECRET_ACCESS_KEY",
      "valueFrom": "/cruddur/backend-flask/AWS_SECRET_ACCESS_KEY"
    },
    {
      "name": "CONNECTION_URL",
      "valueFrom": "/cruddur/backend-flask/CONNECTION_URL"
    },
    {
      "name": "ROLLBAR_ACCESS_TOKEN",
      "valueFrom": "/cruddur/backend-flask/ROLLBAR_ACCESS_TOKEN"
    },
    {
      "name": "OTEL_EXPORTER_OTLP_HEADERS",
      "valueFrom": "/cruddur/backend-flask/OTEL_EXPORTER_OTLP_HEADERS"
    }
  ],
  "environment": [
    {
      "name": "FLASK_APP",
      "value": "app.py"
    }
  ],
  "portMappings": [
    {
      "containerPort": 8080,
      "hostPort": 80,
      "protocol": "tcp"
    }
  ],
  "memoryReservation": 128,
  "cpu": 128,
  "logConfiguration": {
    "logDriver": "awslogs",
    "options": {
      "awslogs-group": "/ecs/backend-flask",
      "awslogs-region": "ca-central-1",
      "awslogs-stream-prefix": "ecs"
    }
  }
}
```

### Create Task and Execution Roles for Task Definition
To run a task in Amazon ECS, we need to create an execution role and a task role. The execution role is used by the Amazon ECS container agent to pull the Docker image and write logs to CloudWatch Logs. The task role is used by the containers in the task to access AWS resources.

### Create Execution Role
We can create an execution role using the following command:

```sh
aws iam create-role \
    --role-name CruddurServiceExecutionRole \
    --assume-role-policy-document "{
  \"Version\":\"2012-10-17\",
  \"Statement\":[{
    \"Action\":[\"sts:AssumeRole\"],
    \"Effect\":\"Allow\",
    \"Principal\":{
      \"Service\":[\"ecs-tasks.amazonaws.com\"]
    }
  }]
}"
```
We can then attach the Amazon ECS task execution role policy to this role using the following command:

```sh

aws iam attach-role-policy \
    --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy \
    --role-name CruddurServiceExecutionRole
```

We also need to add a policy to allow access to the Parameter Store. We can create a policy using the following JSON:

```json

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "VisualEditor0",
      "Effect": "Allow",
      "Action": [
        "ssm:GetParameters",
        "ssm:GetParameter"
      ],
      "Resource": "arn:aws:ssm:ca-central-1:387543059434:parameter/cruddur/backend-flask/*"
    }
  ]
}
```

We can then create a policy and attach it to the execution role using the following commands:

```sh

aws iam create-policy \
    --policy-name CruddurServiceExecutionPolicy \
    --policy-document file://aws/policies/service-execution-policy.json

aws iam attach-role-policy \
    --policy-arn POLICY_ARN \
    --role-name CruddurServiceExecutionRole
```

#### Create Task Role
We can create a task role using the following command:

```sh

aws iam create-role \
    --role-name CruddurTaskRole \
    --assume-role-policy-document "{
  \"Version\":\"2012-10-17\",
  \"Statement\":[{
    \"Action\":[\"sts:AssumeRole\"],
    \"Effect\":\"Allow\",
    \"Principal\":{
      \"Service\":[\"ecs-tasks.amazonaws.com\"]
    }
  }]
}"
```

We can then attach policies to this role to allow access to AWS resources. For example, we can attach the CloudWatch Logs policy and the AWS X-Ray policy using the following commands:

```sh

aws iam attach-role-policy \
    --policy-arn arn:aws:iam::aws:policy/CloudWatchFullAccess \
    --role-name CruddurTaskRole

aws iam attach-role-policy \
    --policy-arn arn:aws:iam::aws:policy/AWSXRayDaemonWriteAccess \
    --role-name CruddurTaskRole
```

We can also create a policy to allow the task role to access the Parameter Store and attach it to the task role using the following commands:

```sh

aws iam create-policy \
    --policy-name SSMAccessPolicy \
    --policy-document "{
  \"Version\":\"2012-10-17\",
  \"Statement\":[{
    \"Action\":[
      \"ssmmessages:CreateControlChannel\",
      \"ssmmessages:CreateDataChannel\",
      \"ssmmessages:OpenControlChannel\",
      \"ssmmessages:OpenDataChannel\"
    ],
    \"Effect\":\"Allow\",
    \"Resource\":\"*\"
  }]
}
"

aws iam attach-role-policy \
    --policy-arn arn:aws:iam::aws:policy/SSMAccessPolicy \
    --role-name CruddurTaskRole
```

That's it for creating task and execution roles for our task definition!

### Create Json file
Create a new folder called `aws/task-defintions` and place the following files in there:

`backend-flask.json`

```json
{
  "family": "backend-flask",
  "executionRoleArn": "arn:aws:iam::AWS_ACCOUNT_ID:role/CruddurServiceExecutionRole",
  "taskRoleArn": "arn:aws:iam::AWS_ACCOUNT_ID:role/CruddurTaskRole",
  "networkMode": "awsvpc",
  "containerDefinitions": [
    {
      "name": "backend-flask",
      "image": "BACKEND_FLASK_IMAGE_URL",
      "cpu": 256,
      "memory": 512,
      "essential": true,
      "portMappings": [
        {
          "name": "backend-flask",
          "containerPort": 4567,
          "protocol": "tcp", 
          "appProtocol": "http"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
            "awslogs-group": "cruddur",
            "awslogs-region": "ca-central-1",
            "awslogs-stream-prefix": "backend-flask"
        }
      },
      "environment": [
        {"name": "OTEL_SERVICE_NAME", "value": "backend-flask"},
        {"name": "OTEL_EXPORTER_OTLP_ENDPOINT", "value": "https://api.honeycomb.io"},
        {"name": "AWS_COGNITO_USER_POOL_ID", "value": ""},
        {"name": "AWS_COGNITO_USER_POOL_CLIENT_ID", "value": ""},
        {"name": "FRONTEND_URL", "value": ""},
        {"name": "BACKEND_URL", "value": ""},
        {"name": "AWS_DEFAULT_REGION", "value": ""}
      ],
      "secrets": [
        {"name": "AWS_ACCESS_KEY_ID"    , "valueFrom": "arn:aws:ssm:AWS_REGION:AWS_ACCOUNT_ID:parameter/cruddur/backend-flask/AWS_ACCESS_KEY_ID"},
        {"name": "AWS_SECRET_ACCESS_KEY", "valueFrom": "arn:aws:ssm:AWS_REGION:AWS_ACCOUNT_ID:parameter/cruddur/backend-flask/AWS_SECRET_ACCESS_KEY"},
        {"name": "CONNECTION_URL"       , "valueFrom": "arn:aws:ssm:AWS_REGION:AWS_ACCOUNT_ID:parameter/cruddur/backend-flask/CONNECTION_URL" },
        {"name": "ROLLBAR_ACCESS_TOKEN" , "valueFrom": "arn:aws:ssm:AWS_REGION:AWS_ACCOUNT_ID:parameter/cruddur/backend-flask/ROLLBAR_ACCESS_TOKEN" },
        {"name": "OTEL_EXPORTER_OTLP_HEADERS" , "valueFrom": "arn:aws:ssm:AWS_REGION:AWS_ACCOUNT_ID:parameter/cruddur/backend-flask/OTEL_EXPORTER_OTLP_HEADERS" }
        
      ]
    }
  ]
}
```

`frontend-react.json`

```json
{
  "family": "frontend-react-js",
  "executionRoleArn": "arn:aws:iam::AWS_ACCOUNT_ID:role/CruddurServiceExecutionRole",
  "taskRoleArn": "arn:aws:iam::AWS_ACCOUNT_ID:role/CruddurTaskRole",
  "networkMode": "awsvpc",
  "containerDefinitions": [
    {
      "name": "frontend-react-js",
      "image": "BACKEND_FLASK_IMAGE_URL",
      "cpu": 256,
      "memory": 256,
      "essential": true,
      "portMappings": [
        {
          "name": "frontend-react-js",
          "containerPort": 3000,
          "protocol": "tcp", 
          "appProtocol": "http"
        }
      ],

      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
            "awslogs-group": "cruddur",
            "awslogs-region": "ca-central-1",
            "awslogs-stream-prefix": "frontend-react"
        }
      }
    }
  ]
}
```

### Register Task Definition
To register the task definition for our backend Flask and frontend React.js services on Amazon Elastic Container Service (ECS), we can use the following commands:

```sh

aws ecs register-task-definition --cli-input-json file://aws/task-definitions/backend-flask.json
```

```sh

aws ecs register-task-definition --cli-input-json file://aws/task-definitions/frontend-react-js.json
```

### Create Security Group
To create a security group for our Cruddur services on ECS, we can use the following command:

```sh

export CRUD_SERVICE_SG=$(aws ec2 create-security-group \
  --group-name "crud-srv-sg" \
  --description "Security group for Cruddur services on ECS" \
  --vpc-id $DEFAULT_VPC_ID \
  --query "GroupId" --output text)
echo $CRUD_SERVICE_SG
```

Here, we create a new security group, name it crud-srv-sg, and set its description to "Security group for Cruddur services on ECS". We also associate this security group with the default VPC of our AWS account, which is specified by the \$DEFAULT_VPC_ID variable. We store the security group ID in the \$CRUD_SERVICE_SG variable.

To allow inbound traffic to the security group, we can use the following command:

```sh

aws ec2 authorize-security-group-ingress \
  --group-id $CRUD_SERVICE_SG \
  --protocol tcp \
  --port 80 \
  --cidr 0.0.0.0/0
```
This command authorizes inbound traffic to the security group by allowing TCP traffic on port 80 from any IP address.

If we need to retrieve the security group ID again, we can use the following command:

```sh

export CRUD_SERVICE_SG=$(aws ec2 describe-security-groups \
  --filters Name=group-name,Values=crud-srv-sg \
  --query 'SecurityGroups[*].GroupId' \
  --output text)
```

#### Update RDS Security Group to Allow Access for the Last Security Group
To allow inbound traffic from the last security group to our Amazon Relational Database Service (RDS) instance, we can use the following command:

```sh
aws ec2 authorize-security-group-ingress \
  --group-id $DB_SG_ID \
  --protocol tcp \
  --port 5432 \
  --source-group $CRUD_SERVICE_SG \
  --tag-specifications 'ResourceType=security-group,Tags=[{Key=Name,Value=BACKENDFLASK}]'
```

Here, we authorize inbound traffic to the security group associated with our RDS instance (\$DB_SG_ID) by allowing TCP traffic on port 5432 from the security group associated with our Cruddur services on ECS (\$CRUD_SERVICE_SG). We also add a tag to the security group to identify it as associated with our backend Flask service.

### Create Services
To create services for our backend Flask and frontend React.js containers on Amazon Elastic Container Service (ECS), we can use the following commands:

```sh

aws ecs create-service --cli-input-json file://aws/json/service-backend-flask.json
```sh

aws ecs create-service --cli-input-json file://aws/json/service-frontend-react-js.json
```

These commands create ECS services for our backend Flask and frontend React.js containers based on the task definitions we registered earlier.

Note that the Auto Assign option is not supported by the EC2 launch type for services. If we are using a NetworkMode of awsvpc, we can use the following option to configure the network for our services:

```sh

--network-configuration "awsvpcConfiguration={subnets=[$DEFAULT_SUBNET_IDS],securityGroups=[$SERVICE_CRUD_SG],assignPublicIp=ENABLED}"
```

This option specifies the IDs of the subnets and security groups to associate with our services, and also enables automatic public IP assignment for the tasks running in our services.

### Test Service
To test our services, we can use AWS Systems Manager Session Manager to connect to the EC2 instances running our containers.

Once connected, we can test the connection to our Amazon Relational Database Service (RDS) instance by running the ./bin/db/test script in the backend Flask container. This script checks if the Flask app is able to connect to the RDS instance.

We can also test if the Flask app is running by running the ./bin/flask/health-check script in the backend Flask container. This script checks if the Flask app is responding to HTTP requests.

To check the endpoint of the Flask app, we can use the following command to get the port that the container is forwarding to:

```sh

docker port <CONTAINER_ID>
```
Then, we can use the following command to test the endpoint:

```sh

docker run --rm --link <CONTAINER_NAME_OR_ID>:<ALIAS> curlimages/curl curl <ALIAS>:<PORT>/<ENDPOINT>
```

For example, to test the GET /api/activities/home endpoint of the Flask app running in the flask container, we can use the following command:

```sh

docker run --rm --link d71eea0b8e93:flask -it curlimages/curl --get -H "Accept: application/json" -H "Content-Type: application/json" http://flask:4567/api/activities/home
```

To test the endpoint against the public IP of the EC2 instance, we can use the following command:

```sh

docker run --rm -it curlimages/curl --get -H "Accept: application/json" -H "Content-Type: application/json" http://<PUBLIC_IP>/api/activities/home
```

If we are not able to use Sessions Manager to connect to the EC2 instance, we can use the AWS CLI to reboot the instance with the following command:

```sh

aws ec2 reboot-instances --instance-ids <INSTANCE_ID>
```

This will force a restart of the instance after 5 minutes. If a graceful shutdown is not successful, the CLI will perform a forceful shutdown after a period of time.

### Connection via Session Manager (Fargate)
To connect to the backend Flask container in our Fargate cluster using AWS Systems Manager Session Manager, we first need to install the Session Manager plugin on our local machine.

To install the plugin on Ubuntu, we can use the following commands:

```sh

curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/ubuntu_64bit/session-manager-plugin.deb" -o "session-manager-plugin.deb"
sudo dpkg -i session-manager-plugin.deb
```

To verify that the plugin is installed and working correctly, we can use the following command:

```sh

session-manager-plugin
```

Once the plugin is installed and verified, we can use the following command to connect to the backend Flask container:

```sh

aws ecs execute-command  \
--region $AWS_DEFAULT_REGION \
--cluster cruddur \
--task dceb2ebdc11c49caadd64e6521c6b0c7 \
--container backend-flask \
--command "/bin/bash" \
--interactive
```

Here, we use the aws ecs execute-command command to execute a command in the specified container of the specified task in our ECS cluster. We use the --interactive option to start an interactive session.

Once we are connected to the container, we can start the backend Flask app by running the following command:

```sh

docker run --rm \
-p 4567:4567 \
-e AWS_ENDPOINT_URL="http://dynamodb-local:8000" \
-e CONNECTION_URL="postgresql://postgres:password@db:5432/cruddur" \
-e FRONTEND_URL="https://3000-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}" \
-e BACKEND_URL="https://4567-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}" \
-e OTEL_SERVICE_NAME='backend-flask' \
-e OTEL_EXPORTER_OTLP_ENDPOINT="https://api.honeycomb.io" \
-e OTEL_EXPORTER_OTLP_HEADERS="x-honeycomb-team=${HONEYCOMB_API_KEY}" \
-e AWS_XRAY_URL="*4567-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}*" \
-e AWS_XRAY_DAEMON_ADDRESS="xray-daemon:2000" \
-e AWS_DEFAULT_REGION="${AWS_DEFAULT_REGION}" \
-e AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}" \
-e AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}" \
-e ROLLBAR_ACCESS_TOKEN="${ROLLBAR_ACCESS_TOKEN}" \
-e AWS_COGNITO_USER_POOL_ID="${AWS_COGNITO_USER_POOL_ID}" \
-e AWS_COGNITO_USER_POOL_CLIENT_ID="5b6ro31g97urk767adrbrdj1g5" \
-it backend-flask-prod
```

This command starts the backend Flask app in a Docker container with the necessary environment variables and port mappings. Once the Flask app is running, we can test it using the same commands as before.